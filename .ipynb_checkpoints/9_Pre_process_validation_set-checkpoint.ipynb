{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN Main import block and TODO list\n",
    "\n",
    "# TODO: see how uri calculated the ridges\n",
    "\n",
    "# TODO: Perform Histogram equalization - start with it\n",
    "# TODO: \n",
    "# take integral from the Highest peak+-0.005 divide by integral of the entire graph \n",
    "# This will be the peakness measure for the PSD ==> The desired ridge index\n",
    "# TODO:\n",
    "# take integral from the Highest peak+-0.005 divide by integral of the entire graph - it's the peakness measure for the PSD\n",
    "# must select a peak above a min threshold in order to ignore noisy frequency\n",
    "# must ignore peaks above a certain threshold in order to detect meaningful frequency\n",
    "# run the PSD in moving windows every 200 px (deduced from the below PSD pointing to a freq of 1/0.02=50-> times 4= 200px)\n",
    "# and medianf the result of the windows\n",
    "# TODO:\n",
    "# Another alternative: (with Yariv)\n",
    "# Run PSD column by column - get the phase, freq, peakness and reconstruct an artificial ridge slice\n",
    "# from this - reconstruct a \"clean\" artificial ridge image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "import cv2\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import mahotas as mh\n",
    "from mahotas import polygon\n",
    "# import pymorph as pm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "import skimage.transform as transform\n",
    "import skimage.morphology as mp\n",
    "import skimage.io as sio\n",
    "import scipy.misc as sm\n",
    "from skimage.filters import threshold_otsu, threshold_adaptive\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from skimage import exposure\n",
    "from skimage import data, img_as_float\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from bisect import bisect_left\n",
    "import math\n",
    "import warnings\n",
    "import csv\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     16,
     20,
     23,
     41,
     49,
     69,
     83,
     96,
     105,
     112,
     127,
     175,
     192,
     204,
     239,
     245,
     250,
     255,
     262,
     267,
     272,
     280,
     287,
     296
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN Utility functions\n",
    "\n",
    "# One time init\n",
    "# with open('results.csv', 'w') as csvfile:\n",
    "#     csvout = csv.writer(csvfile)\n",
    "#     csvout.writerow([\"File\", \"Model\", \"Gap\", \"Slice_size\", \"Count\", \"Precision\", \"Recall\", \"F-score\", \"True Count\", \"Error Rate\"])\n",
    "\n",
    "#BASIC CROP FRAME\n",
    "X_START = 1000\n",
    "X_END = 5500\n",
    "Y_START = 800\n",
    "Y_END = 4300\n",
    "BG_2_OBJ_RATIO = 0.94\n",
    "CUBE_SIZE = 250\n",
    "\n",
    "# Simple crop by x/y ranges\n",
    "def crop(image, ymin, ymax, xmin, xmax):\n",
    "    return image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "# returns a logical matrix of values beyond a threshld\n",
    "def thresholded(image, val): \n",
    "    return np.logical_and(*[image[...] > val  for t in enumerate([0, 0])])\n",
    "\n",
    "def find_min_max_without_orphand_pixels(nonzero_dimension, crop_filter=20):\n",
    "    sorted = np.sort(nonzero_dimension)\n",
    "    prev=-1\n",
    "    min_val = sorted[0]\n",
    "    for i, x in enumerate(sorted[:100]):\n",
    "        if prev >= 0 and x - prev > crop_filter:\n",
    "            min_val = x\n",
    "        prev = x\n",
    "    prev=-1\n",
    "    max_val = sorted[-1]\n",
    "    for i, x in enumerate(sorted[-100:]):\n",
    "        if prev >= 0 and x - prev > crop_filter:\n",
    "            max_val = prev\n",
    "            break\n",
    "        prev = x\n",
    "    \n",
    "    return min_val, max_val\n",
    "\n",
    "def calc_min_max_coordinates(image, crop_val=50):\n",
    "    temp = thresholded(image, crop_val)\n",
    "    temp = temp * 1\n",
    "    temp = np.nonzero(temp)\n",
    "    ymin, ymax = find_min_max_without_orphand_pixels(temp[0])\n",
    "    xmin,xmax = find_min_max_without_orphand_pixels(temp[1])\n",
    "    return ymin, ymax, xmin, xmax\n",
    "\n",
    "def calc_min_max_coordinates_dynamic(image, cutoff=1):\n",
    "    temp = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
    "    flat = np.sort(np.matrix.getA1(temp))\n",
    "    sum_all = np.sum(flat)\n",
    "    index = np.argmin(flat.cumsum() < (sum_all * cutoff))\n",
    "\n",
    "    temp = thresholded(temp, flat[index])\n",
    "    temp = temp * 1\n",
    "    temp = np.nonzero(temp)\n",
    "    ymin, ymax = find_min_max_without_orphand_pixels(temp[0])\n",
    "    xmin,xmax = find_min_max_without_orphand_pixels(temp[1])\n",
    "    return ymin, ymax, xmin, xmax\n",
    "\n",
    "# initial static crop and a seondary dynamic crop based on signal2noise ratio\n",
    "def crop_full_scan(image, cutoff):\n",
    "    temp = crop(image, Y_START, Y_END, X_START, X_END)\n",
    "    ymin, ymax, xmin, xmax = calc_min_max_coordinates_dynamic(temp, cutoff)\n",
    "    temp = crop(image, Y_START+ymin, Y_START+ymax, X_START+xmin, X_START+xmax)\n",
    "    return temp\n",
    "\n",
    "def crop_thresholded(image):\n",
    "    temp = crop(image, 0, image.shape[0]-1, 0, image.shape[1]-1)\n",
    "    ymin, ymax, xmin, xmax = calc_min_max_coordinates(temp)\n",
    "    temp = crop(image, ymin, ymax, xmin, xmax)\n",
    "    return temp\n",
    "\n",
    "def read_full_path_and_crop(image_name, cutoff=BG_2_OBJ_RATIO):\n",
    "    image = img.imread(image_name)\n",
    "\n",
    "    # Smart-crop the image to get rid of all the noise and redundant area\n",
    "    # return crop_full_scan(image)\n",
    "    cropped = crop_full_scan(image, cutoff)\n",
    "    return exposure.equalize_adapthist(cropped, clip_limit=0.03)\n",
    "\n",
    "def read_and_crop(image_name):\n",
    "    if \"il239838\" in os.getcwd():\n",
    "        image = img.imread(\"/Users/il239838/Downloads/private/Thesis/Papyrus/\" + image_name)\n",
    "    else:\n",
    "        f = urllib.request.urlopen(\"https://dl.dropboxusercontent.com/s/31b96942qdcn73k/\" + image_name)\n",
    "        image = img.imread(f, format='jpeg')\n",
    "\n",
    "    # Smart-crop the image to get rid of all the noise and redundant area\n",
    "    # return crop_full_scan(image)\n",
    "    cropped = crop_full_scan(image)\n",
    "    return exposure.equalize_adapthist(cropped, clip_limit=0.03)\n",
    "\n",
    "# TODO: fix performance!!! http://scikit-image.org/docs/dev/user_guide/tutorial_parallelization.html\n",
    "def combine_3_images_to_RGB(red, green, blue):\n",
    "    new_image = np.empty((blue.shape[0],blue.shape[1],3))\n",
    "    for x in range(0, blue.shape[0]):\n",
    "        for y in range(0, blue.shape[1]):\n",
    "            new_image[x,y,0] = red[x,y]\n",
    "            new_image[x,y,1] = green[x,y]\n",
    "            new_image[x,y,2] = blue[x,y]\n",
    "    return new_image\n",
    "\n",
    "def slice_image_left_edge_no_adapt(original, width=200, rotate=0):\n",
    "    rot = ndimage.rotate(original, rotate)\n",
    "    # Slice the left slice of the so-called \"blue\" image\n",
    "    left_edge_orig = crop(rot, 0, 1400, 0, width)\n",
    "    \n",
    "    return left_edge_orig\n",
    "\n",
    "def slice_image_left_edge(original, width=200, rotate=0):\n",
    "    rot = ndimage.rotate(original, rotate)\n",
    "    # Slice the left slice of the so-called \"blue\" image\n",
    "    left_edge_orig = crop(rot, 0, 1400, 0, width)\n",
    "    left_edge_orig = crop_thresholded(left_edge_orig)\n",
    "\n",
    "    # Copy to a new array so we don't thrash the origin\n",
    "    left_edge = np.empty_like (left_edge_orig)\n",
    "    np.copyto(left_edge, left_edge_orig)\n",
    "\n",
    "    # Zero down low level \"noise\" values\n",
    "    low_values_indices = left_edge < 30  # Where values are low\n",
    "    left_edge[low_values_indices] = 0  # All low values set to 0\n",
    "    return left_edge\n",
    "\n",
    "def get_best_angle_rotation(original, crop=True, width=200):\n",
    "    min_var = 99999999999\n",
    "    best_angle = -10\n",
    "    for x in range(-5,5):\n",
    "        if crop:            \n",
    "            rot_edge = slice_image_left_edge(original, width, x)\n",
    "        else:\n",
    "            rot_edge = ndimage.rotate(original, x)\n",
    "        left_var = np.var(rot_edge, axis=1)\n",
    "        # left_var = np.apply_along_axis(lambda v: np.var(v[np.nonzero(v)]), 1, rot_edge)\n",
    "        var_sum = np.sum(left_var)\n",
    "        if (var_sum < min_var):\n",
    "            min_var = var_sum\n",
    "            best_angle = x\n",
    "    print (\"best_angle=\"+str(best_angle))\n",
    "    return best_angle\n",
    "\n",
    "def get_best_orientation(original, crop=True, width=200):\n",
    "    min_var = 99999999999\n",
    "    best_angle = 0\n",
    "    #import pdb; pdb.set_trace()\n",
    "    for x in [0, 90]:\n",
    "        if crop:            \n",
    "            rot_edge = slice_image_left_edge_no_adapt(original, width, x)\n",
    "        else:\n",
    "            rot_edge = ndimage.rotate(original, x)\n",
    "        left_var = np.var(rot_edge, axis=1)\n",
    "        # USE NEXT BLOCK if having issues with variance including zero values\n",
    "        # low_values_indices = rot_edge < 0.12\n",
    "        # rot_edge[low_values_indices] = 0\n",
    "        # left_var = np.apply_along_axis(lambda v: np.var(v[np.nonzero(v)]), 1, rot_edge)\n",
    "        var_sum = np.sum(left_var)\n",
    "        if (var_sum < min_var):\n",
    "            min_var = var_sum\n",
    "            best_angle = x\n",
    "    print (\"best_angle=\"+str(best_angle))\n",
    "    return best_angle\n",
    "\n",
    "def get_manual_orientation(original, crop=True, width=200):\n",
    "    rot1 = ndimage.rotate(original, 90)\n",
    "    plot_comparison(original, rot1, \"Rotated\")\n",
    "    input_var = input(\"Enter 1 to rotate and 0 to keep as-is: \")\n",
    "    print (\"you entered \" + input_var) \n",
    "    \n",
    "    return input_var\n",
    "\n",
    "\n",
    "#     import pdb; pdb.set_trace()\n",
    "def calc_neighbors(slice_map, col, row):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    if ((col-1, row) in slice_map and slice_map[(col-1, row)] != None):\n",
    "        slice_map[(col, row)][\"left\"] = slice_map[(col-1, row)]\n",
    "        slice_map[(col-1, row)][\"right\"] = slice_map[(col, row)]\n",
    "    if ((col+1, row) in slice_map and slice_map[(col+1, row)] != None):\n",
    "        slice_map[(col, row)][\"right\"] = slice_map[(col+1, row)]\n",
    "        slice_map[(col+1, row)][\"left\"] = slice_map[(col, row)]\n",
    "    if ((col, row-1) in slice_map and slice_map[(col, row-1)] != None):\n",
    "        slice_map[(col, row)][\"top\"] = slice_map[(col, row-1)]\n",
    "        slice_map[(col, row-1)][\"bottom\"] = slice_map[(col, row)]\n",
    "    if ((col, row+1) in slice_map and slice_map[(col, row+1)] != None):\n",
    "        slice_map[(col, row)][\"bottom\"] = slice_map[(col, row+1)]\n",
    "        slice_map[(col, row+1)][\"top\"] = slice_map[(col, row)]\n",
    "    \n",
    "\n",
    "\n",
    "def create_cube(raw, x, y):\n",
    "    cube = {}\n",
    "    cube[\"cube\"] = raw\n",
    "    cube[\"top_row\"] = x\n",
    "    cube[\"left_col\"] = y\n",
    "    cube[\"right_col\"] = y + CUBE_SIZE\n",
    "    return cube\n",
    "    \n",
    "\n",
    "ZERO_CUBE = create_cube(np.zeros((CUBE_SIZE, CUBE_SIZE), dtype=np.int), -1, -2)\n",
    "\n",
    "# slice an image to cubes with 250X250 pixel size\n",
    "def slice_to_static_slices(cropped_original):\n",
    "    structure = {}\n",
    "    # cropped_original = cropped_original / 256 # divide by 256 to \"normalize\" between 0 and 1\n",
    "    x, y = cropped_original.shape\n",
    "    print (x,y)\n",
    "    n = 0\n",
    "    # every 250 pixels on the x axis == rows\n",
    "    while ((n + 1) * CUBE_SIZE < x):\n",
    "        m = 0\n",
    "        # every 250 pixels on the y axis == cols\n",
    "        while ((m + 1) * CUBE_SIZE < y):\n",
    "            # cut a cube of 250X250\n",
    "            cube = (crop(cropped_original, n * CUBE_SIZE, (n + 1) * CUBE_SIZE, m * CUBE_SIZE, (m + 1) * CUBE_SIZE))\n",
    "            # keep only cubes for which half of the pixels have some \"color\"\n",
    "            # import pdb; pdb.set_trace()\n",
    "            # print(np.median(cube))\n",
    "            if np.median(cube) > 0.2: # aligned with the normalization 0.2 correlates to 50\n",
    "                # keep the cube\n",
    "                structure[(m, n)] = create_cube(cube, n * CUBE_SIZE, m * CUBE_SIZE)\n",
    "                structure[(m, n)][\"col\"] = m\n",
    "                structure[(m, n)][\"row\"] = n\n",
    "            else:\n",
    "                structure[(m, n)] = None\n",
    "            m += 1\n",
    "        n += 1\n",
    "    \n",
    "    # this loop has to be performed only after we've established all the None cubes\n",
    "    for cube in structure.values():\n",
    "        # set the reference to neighbor cubes\n",
    "        if cube != None:\n",
    "            calc_neighbors(structure, cube[\"col\"], cube[\"row\"])\n",
    "        \n",
    "    # return the data structure with all the cubes and the counters of the rows and columns\n",
    "    return structure, m, n\n",
    "\n",
    "def pad_above(original, above, amount):\n",
    "    res = np.insert(original[\"cube\"], np.zeros(amount), above[\"cube\"][-amount:], axis=0)\n",
    "    res = np.delete(res, np.arange(CUBE_SIZE,CUBE_SIZE+amount), axis=0)\n",
    "    return create_cube(res, original[\"top_row\"] - amount, original[\"left_col\"])\n",
    "  \n",
    "\n",
    "def pad_below(original, below, amount):\n",
    "    res = np.insert(original[\"cube\"], np.full(amount, CUBE_SIZE), below[\"cube\"][:amount], axis=0)\n",
    "    res = np.delete(res, np.arange(0, amount), axis=0)\n",
    "    return create_cube(res, original[\"top_row\"] + amount, original[\"left_col\"])\n",
    "\n",
    "def pad_left(original, left, amount):\n",
    "    res = np.insert(original[\"cube\"], np.zeros(amount, dtype=int), left[\"cube\"][:,-amount:], axis=1)\n",
    "    res = np.delete(res, np.arange(CUBE_SIZE, CUBE_SIZE+amount), axis=1)\n",
    "    return create_cube(res, original[\"top_row\"], original[\"left_col\"] - amount)\n",
    "\n",
    "def pad_right(original, right, amount):\n",
    "    res = np.insert(original[\"cube\"], [CUBE_SIZE], right[\"cube\"][:,:amount], axis=1)\n",
    "    res = np.delete(res, np.arange(0, amount), axis=1)\n",
    "    return create_cube(res, original[\"top_row\"], original[\"left_col\"] + amount)\n",
    "    \n",
    "\n",
    "# \"Shave\" the right edge of the cube with <gap> pixels and pad with zeros on the left\n",
    "def shave_right(original, amount):\n",
    "    return pad_left(original, ZERO_CUBE, amount)\n",
    "    \n",
    "\n",
    "# \"Shave\" the left edge of the cube with <gap> pixels and pad with zeros on the right    \n",
    "def shave_left(original, amount):\n",
    "    return pad_right(original, ZERO_CUBE, amount)\n",
    "    \n",
    "\n",
    "# concatenate cubes \n",
    "def concatenate_cubes(left, right, slice_size):\n",
    "    con = np.concatenate((left[\"cube\"][:,-slice_size:], right[\"cube\"][:,:slice_size]), axis=1)\n",
    "    x_delta = right[\"top_row\"] - left[\"top_row\"]\n",
    "    y_delta = right[\"left_col\"] - left[\"right_col\"] \n",
    "    return con, x_delta, y_delta\n",
    "    \n",
    "\n",
    "# concatenate cubes while artificially creating a gap between them. Pad the other end of the cube with zeros\n",
    "def concatenate_cubes_zero_pad_gaps(left_orig, right_orig, gap):\n",
    "    left = left_orig if gap == 0 else shave_right(left_orig, gap)\n",
    "    right = right_orig if gap == 0 else shave_left(right_orig, gap)\n",
    "    return concatenate_cubes(left, right)    \n",
    "\n",
    "# concatenate cubes while artificially creating a gap between them. Pad the other end of the cobe with the nearby\n",
    "# continuation of the cubes\n",
    "def concatenate_cubes_with_gap(left_orig, right_orig, gap, left_pad, right_pad, slice_size):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    left = left_orig if gap == 0 else pad_left(left_orig, left_pad, gap)\n",
    "    right = right_orig if gap == 0 else pad_right(right_orig, right_pad, gap)\n",
    "    return concatenate_cubes(left, right, slice_size)        \n",
    "\n",
    "# convert the data structure of cubes into a train set of 2 arrays of images and labels\n",
    "# each image is a concatanation of 2 images from the original cubes set, covering all combinations of images\n",
    "# effectively creating Nx(N-1) images\n",
    "def build_train_set(rows, cols, cubes, gap, slice_size):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    train_imgs = []\n",
    "    train_lbls = []\n",
    "    train_x_delta = []\n",
    "    train_y_delta = []\n",
    "    # iterate over the rows and cols, essentially going over the grid of sliced cubes\n",
    "    for row in range(0, rows):\n",
    "        for col in range(0, cols):\n",
    "            # if this cube exists (could have been removed previously due to lack of data)\n",
    "            if (cubes[(col, row)] != None):\n",
    "                # for each \"current\" image in the iteration\n",
    "                curr = cubes[(col, row)]\n",
    "                # iterate over all the cubes to find all the \"other\" (adjacent) cubes\n",
    "                for adj_row in range(0, rows):\n",
    "                    for adj_col in range(0, cols):\n",
    "                        if (adj_row != row or adj_col != col):\n",
    "                            if (cubes[(adj_col, adj_row)] != None):\n",
    "                                adj = cubes[(adj_col, adj_row)]\n",
    "                                # append the adjacent image to the current image\n",
    "                                # pass the filling cubes on the right and left to pad against the gap\n",
    "                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys())):\n",
    "                                    if (gap == 0):\n",
    "                                        conc, x_delta, y_delta = concatenate_cubes(curr, adj, slice_size)\n",
    "                                    else:\n",
    "                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr, adj, gap, curr[\"left\"], adj[\"right\"], slice_size)\n",
    "                                    train_imgs.append(conc)\n",
    "                                    train_x_delta.append(x_delta)\n",
    "                                    train_y_delta.append(y_delta)\n",
    "                                    # if the adj image is on the same row and on the right of the curr image - it will be marked as match    \n",
    "                                    if (adj_row == row and adj_col == (col + 1)):\n",
    "                                        # mark the image as matched\n",
    "                                        train_lbls.append([0,1])\n",
    "                                        # need to enrich the set with a few more tru positive samples - so we offset \n",
    "                                        # the matched images up ad down a few times and create more matches\n",
    "                                        if (\"top\" in curr.keys() and \"top\"in adj.keys()):\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_above(curr, curr[\"top\"],i)\n",
    "                                                adj1 = pad_above(adj, adj[\"top\"],i)\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys() and \"top\" in curr[\"left\"].keys() and \"top\"in curr[\"right\"].keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_above(curr[\"left\"], curr[\"left\"][\"top\"], i) # FIXIT?\n",
    "                                                        adj1Right = pad_above(adj[\"right\"], curr[\"right\"][\"top\"], i) # FIXIT?\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                        if (\"bottom\" in curr.keys() and \"bottom\"in adj.keys()):\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_below(curr, curr[\"bottom\"],i)\n",
    "                                                adj1 = pad_below(adj, adj[\"bottom\"],i)\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys() and \"bottom\" in curr[\"left\"].keys() and \"bottom\"in curr[\"right\"].keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_below(curr[\"left\"], curr[\"left\"][\"bottom\"], i) # FIXIT?\n",
    "                                                        adj1Right = pad_below(adj[\"right\"], curr[\"right\"][\"bottom\"], i) # FIXIT?\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                        if (\"left\" in curr.keys()): # enough to check only the curr as the left of the adj is the curr\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_left(curr, curr[\"left\"],i)\n",
    "                                                adj1 = pad_left(adj, adj[\"left\"],i) # essentially the curr\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_left(curr[\"left\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        adj1Right = pad_left(adj[\"right\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                        if (\"right\" in adj.keys()): # enough to check only the adj as the right of the curr is the adj\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_right(curr, curr[\"right\"],i) # essentially the adj\n",
    "                                                adj1 = pad_right(adj, adj[\"right\"],i)\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_right(curr[\"left\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        adj1Right = pad_right(adj[\"right\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                    else:\n",
    "                                        # mark the image as not matched\n",
    "                                        train_lbls.append([1,0])\n",
    "                                \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return train_imgs, train_lbls, train_x_delta, train_y_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN Image utility functions (external source)\n",
    "def branchedPoints(skel):\n",
    "    branch1=np.array([[2, 1, 2], [1, 1, 1], [2, 2, 2]])\n",
    "    branch2=np.array([[1, 2, 1], [2, 1, 2], [1, 2, 1]])\n",
    "    branch3=np.array([[1, 2, 1], [2, 1, 2], [1, 2, 2]])\n",
    "    branch4=np.array([[2, 1, 2], [1, 1, 2], [2, 1, 2]])\n",
    "    branch5=np.array([[1, 2, 2], [2, 1, 2], [1, 2, 1]])\n",
    "    branch6=np.array([[2, 2, 2], [1, 1, 1], [2, 1, 2]])\n",
    "    branch7=np.array([[2, 2, 1], [2, 1, 2], [1, 2, 1]])\n",
    "    branch8=np.array([[2, 1, 2], [2, 1, 1], [2, 1, 2]])\n",
    "    branch9=np.array([[1, 2, 1], [2, 1, 2], [2, 2, 1]])\n",
    "    br1=mh.morph.hitmiss(skel,branch1)\n",
    "    br2=mh.morph.hitmiss(skel,branch2)\n",
    "    br3=mh.morph.hitmiss(skel,branch3)\n",
    "    br4=mh.morph.hitmiss(skel,branch4)\n",
    "    br5=mh.morph.hitmiss(skel,branch5)\n",
    "    br6=mh.morph.hitmiss(skel,branch6)\n",
    "    br7=mh.morph.hitmiss(skel,branch7)\n",
    "    br8=mh.morph.hitmiss(skel,branch8)\n",
    "    br9=mh.morph.hitmiss(skel,branch9)\n",
    "    return br1+br2+br3+br4+br5+br6+br7+br8+br9\n",
    "\n",
    "def endPoints(skel):\n",
    "    endpoint1=np.array([[0, 0, 0],\n",
    "                        [0, 1, 0],\n",
    "                        [2, 1, 2]])\n",
    "    \n",
    "    endpoint2=np.array([[0, 0, 0],\n",
    "                        [0, 1, 2],\n",
    "                        [0, 2, 1]])\n",
    "    \n",
    "    endpoint3=np.array([[0, 0, 2],\n",
    "                        [0, 1, 1],\n",
    "                        [0, 0, 2]])\n",
    "    \n",
    "    endpoint4=np.array([[0, 2, 1],\n",
    "                        [0, 1, 2],\n",
    "                        [0, 0, 0]])\n",
    "    \n",
    "    endpoint5=np.array([[2, 1, 2],\n",
    "                        [0, 1, 0],\n",
    "                        [0, 0, 0]])\n",
    "    \n",
    "    endpoint6=np.array([[1, 2, 0],\n",
    "                        [2, 1, 0],\n",
    "                        [0, 0, 0]])\n",
    "    \n",
    "    endpoint7=np.array([[2, 0, 0],\n",
    "                        [1, 1, 0],\n",
    "                        [2, 0, 0]])\n",
    "    \n",
    "    endpoint8=np.array([[0, 0, 0],\n",
    "                        [2, 1, 0],\n",
    "                        [1, 2, 0]])\n",
    "    \n",
    "    ep1=mh.morph.hitmiss(skel,endpoint1)\n",
    "    ep2=mh.morph.hitmiss(skel,endpoint2)\n",
    "    ep3=mh.morph.hitmiss(skel,endpoint3)\n",
    "    ep4=mh.morph.hitmiss(skel,endpoint4)\n",
    "    ep5=mh.morph.hitmiss(skel,endpoint5)\n",
    "    ep6=mh.morph.hitmiss(skel,endpoint6)\n",
    "    ep7=mh.morph.hitmiss(skel,endpoint7)\n",
    "    ep8=mh.morph.hitmiss(skel,endpoint8)\n",
    "    ep = ep1+ep2+ep3+ep4+ep5+ep6+ep7+ep8\n",
    "    return ep\n",
    "\n",
    "def pruning(skeleton, size):\n",
    "    '''remove iteratively end points \"size\" \n",
    "       times from the skeleton\n",
    "    '''\n",
    "    for i in range(0, size):\n",
    "        endpoints = endPoints(skeleton)\n",
    "        endpoints = np.logical_not(endpoints)\n",
    "        skeleton = np.logical_and(skeleton,endpoints)\n",
    "    return skeleton\n",
    "\n",
    "def plot_comparison(original, filtered, filter_name):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "    ax1.imshow(original, cmap=plt.cm.gray)\n",
    "    ax1.set_title('original')\n",
    "    ax1.axis('off')\n",
    "    ax1.set_adjustable('box-forced')\n",
    "    ax2.imshow(filtered, cmap=plt.cm.gray)\n",
    "    ax2.set_title(filter_name)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_adjustable('box-forced')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pre-process the validation set\n",
    "def folder_walker(path, full_path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file_ in files:\n",
    "            if \"-V-\" in file_ and \"924 \" in file_ and not file_.startswith(\".\"):\n",
    "                # print(os.path.join(root, file_))\n",
    "                if full_path:\n",
    "                    result.append( os.path.join(root, file_) )\n",
    "                else:\n",
    "                    result.append(file_)\n",
    "    return result\n",
    "\n",
    "input_files = folder_walker(\"/Volumes/250GB/PAPYRI\", True)\n",
    "no_rotate = folder_walker(\"/Volumes/250GB/rotate\", False)\n",
    "extra_crop = folder_walker(\"/Volumes/250GB/crop_more\", False)\n",
    "#input_files = folder_walker(\"/Volumes/250GB/P589-Fg011-V\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/250gb/cropped_bw/P589-Fg001-V-C01-R01-D12022013-T111041-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg002-V-C01-R01-D12022013-T112327-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg003-V-C01-R01-D12022013-T114206-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg004-V-C01-R01-D12022013-T115050-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg005-V-C01-R01-D12022013-T115924-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg006-V-C01-R01-D12022013-T121151-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P589-Fg007-V-C01-R01-D12022013-T122119-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg008-V-C01-R01-D12022013-T122948-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg009-V-C01-R01-D12022013-T123809-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg010-V-C01-R01-D12022013-T124734-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg011-V-C01-R01-D12022013-T125605-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P589-Fg012-V-C01-R01-D12022013-T130436-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg001-V-C01-R01-D19012014-T115811-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P596-Fg002-V-C01-R01-D19012014-T120740-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg003-V-C01-R01-D19012014-T121702-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg004-V-C01-R01-D19012014-T122738-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg005-V-C01-R01-D19012014-T131003-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P596-Fg006-V-C01-R01-D19012014-T131956-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P596-Fg007-V-C01-R01-D19012014-T132951-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P596-Fg008-V-C01-R01-D19012014-T133807-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg009-V-C01-R01-D19012014-T134750-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg010-V-C01-R01-D19012014-T140041-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg011-V-C01-R01-D19012014-T140918-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P596-Fg012-V-C01-R01-D19012014-T142013-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg013-V-C01-R01-D19012014-T142832-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg014-V-C01-R01-D19012014-T143659-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg015-V-C01-R01-D19012014-T144447-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg016-V-C01-R01-D10122014-T093201-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg017-V-C01-R01-D19012014-T150244-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg018-V-C01-R01-D19012014-T151147-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg019-V-C01-R01-D19012014-T152015-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg020-V-C01-R01-D19012014-T152906-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg021-V-C01-R01-D19012014-T153726-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg022-V-C01-R01-D20012014-T094749-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg023-V-C01-R01-D20012014-T095602-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg024-V-C01-R01-D20012014-T100408-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg025-V-C01-R01-D20012014-T101404-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg026-V-C01-R01-D20012014-T102223-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg027-V-C01-R01-D20012014-T103241-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg028-V-C01-R01-D20012014-T104238-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg029-V-C01-R01-D20012014-T105217-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg030-V-C01-R01-D20012014-T110030-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg031-V-C01-R01-D20012014-T110913-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg032-V-C01-R01-D20012014-T113905-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg033-V-C01-R01-D20012014-T112908-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg034-V-C01-R01-D20012014-T114842-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P596-Fg035-V-C01-R01-D20012014-T115703-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg036-V-C01-R01-D20012014-T120603-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg037-V-C01-R01-D20012014-T121420-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg038-V-C01-R01-D20012014-T122453-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg039-V-C01-R01-D20012014-T131904-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg040-V-C01-R01-D20012014-T134202-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg041-V-C01-R01-D20012014-T133742-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg042-V-C01-R01-D20012014-T135626-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P596-Fg043-V-C01-R01-D20012014-T140501-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg044-V-C01-R01-D20012014-T141520-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg045-V-C01-R01-D20012014-T142324-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg046-V-C01-R01-D20012014-T143130-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg047-V-C01-R01-D20012014-T144010-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg048-V-C01-R01-D20012014-T144844-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P596-Fg049-V-C01-R01-D20012014-T150057-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg050-V-C01-R01-D20012014-T150949-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg051-V-C01-R01-D20012014-T152806-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg052-V-C01-R01-D22012014-T093913-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg053-V-C01-R01-D22012014-T094731-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg054-V-C01-R01-D22012014-T095704-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg055-V-C01-R01-D22012014-T100545-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg056-V-C01-R01-D22012014-T101422-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg057-V-C01-R01-D22012014-T102254-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg058-V-C01-R01-D22012014-T103301-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg059-V-C01-R01-D22012014-T104139-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg060-V-C01-R01-D22012014-T105019-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg061-V-C01-R01-D22012014-T105847-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg062-V-C01-R01-D22012014-T110702-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg063-V-C01-R01-D22012014-T111549-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg064-V-C01-R01-D22012014-T112456-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg065-V-C01-R01-D22012014-T113512-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg066-V-C01-R01-D22012014-T114938-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg067-V-C01-R01-D22012014-T120005-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg068-V-C01-R01-D22012014-T121824-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg069-V-C01-R01-D22012014-T122658-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg070-V-C01-R01-D22012014-T123533-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg071-V-C01-R01-D22012014-T124910-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg072-V-C01-R01-D22012014-T125734-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg073-V-C01-R01-D22012014-T130547-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg074-V-C01-R01-D22012014-T131422-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg075-V-C01-R01-D22012014-T132259-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P596-Fg076-V-C01-R01-D22012014-T133158-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P596-Fg077-V-C01-R01-D22012014-T134003-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg078-V-C01-R01-D22012014-T134902-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P596-Fg079-V-C01-R01-D22012014-T135725-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P596-Fg080-V-C01-R01-D22012014-T140553-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg081-V-C01-R01-D22012014-T141410-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P596-Fg082-V-C01-R01-D22012014-T142203-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P596-Fg083-V-C01-R01-D22012014-T142948-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P596-Fg084-V-C01-R01-D22012014-T143723-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P596-Fg085-V-C01-R01-D22012014-T144507-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg001-V-C01-R01-D30112014-T101244-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg002-V-C01-R01-D30112014-T102219-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg003-V-C01-R01-D30112014-T103112-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg004-V-C01-R01-D30112014-T110234-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg005-V-C01-R01-D30112014-T111102-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg006-V-C01-R01-D30112014-T111929-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg007-V-C01-R01-D30112014-T112750-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg008-V-C01-R01-D30112014-T113605-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg009-V-C01-R01-D30112014-T114948-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg010-V-C01-R01-D30112014-T123457-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg011-V-C01-R01-D30112014-T124223-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg012-V-C01-R01-D30112014-T125030-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg013-V-C01-R01-D30112014-T131012-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg014-V-C01-R01-D30112014-T131820-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg015-V-C01-R01-D30112014-T132629-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg016-V-C01-R01-D30112014-T133433-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg017-V-C01-R01-D30112014-T135559-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg018-V-C01-R01-D30112014-T140412-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg019-V-C01-R01-D30112014-T141251-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg020-V-C01-R01-D30112014-T142037-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg021-V-C01-R01-D30112014-T142843-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg022-V-C01-R01-D30112014-T143706-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg023-V-C01-R01-D30112014-T144610-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg024-V-C01-R01-D30112014-T145417-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg025-V-C01-R01-D30112014-T150542-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg026-V-C01-R01-D30112014-T151535-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg027-V-C01-R01-D30112014-T152733-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg028-V-C01-R01-D30112014-T153511-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg029-V-C01-R01-D30112014-T154304-ML924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P597-Fg030-V-C01-R01-D30112014-T155059-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg031-V-C01-R01-D01122014-T091426-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg032-V-C01-R01-D01122014-T092225-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg033-V-C01-R01-D01122014-T093035-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg034-V-C01-R01-D01122014-T093820-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg035-V-C01-R01-D01122014-T094616-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg036-V-C01-R01-D01122014-T095450-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg037-V-C01-R01-D01122014-T100335-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg038-V-C01-R01-D01122014-T101144-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg039-V-C01-R01-D01122014-T102022-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg040-V-C01-R01-D01122014-T102944-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg041-V-C01-R01-D01122014-T103748-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg042-V-C01-R01-D01122014-T104603-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg043-V-C01-R01-D01122014-T105516-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg044-V-C01-R01-D01122014-T110342-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg045-V-C01-R01-D01122014-T112140-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg046-V-C01-R01-D01122014-T112932-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg047-V-C01-R01-D01122014-T113733-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg048-V-C01-R01-D01122014-T122926-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg049-V-C01-R01-D01122014-T123827-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg050-V-C01-R01-D01122014-T124611-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg051-V-C01-R01-D01122014-T125527-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg052-V-C01-R01-D01122014-T130308-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg053-V-C01-R01-D01122014-T131534-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg054-V-C01-R01-D01122014-T132347-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg055-V-C01-R01-D01122014-T133303-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg056-V-C01-R01-D01122014-T134150-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg057-V-C01-R01-D01122014-T135318-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg058-V-C01-R01-D01122014-T140145-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg059-V-C01-R01-D01122014-T141034-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg060-V-C01-R01-D01122014-T141912-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg061-V-C01-R01-D01122014-T142857-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg062-V-C01-R01-D01122014-T143728-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg063-V-C01-R01-D01122014-T144518-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg064-V-C01-R01-D01122014-T145307-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg065-V-C01-R01-D01122014-T150706-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg066-V-C01-R01-D01122014-T151554-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg067-V-C01-R01-D02122014-T091115-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg068-V-C01-R01-D02122014-T091910-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg069-V-C01-R01-D02122014-T092706-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P597-Fg070-V-C01-R01-D02122014-T094222-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg071-V-C01-R01-D02122014-T095708-ML924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P597-Fg072-V-C01-R01-D02122014-T100756-ML924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P598-Fg001-V-C01-R01-D07012014-T105645-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg002-V-C01-R01-D07012014-T110442-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P598-Fg003-V-C01-R01-D07012014-T111340-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg004-V-C01-R01-D07012014-T112129-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg005-V-C01-R01-D07012014-T113447-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg006-V-C01-R01-D07012014-T114223-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg007-V-C01-R01-D07012014-T115035-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg008-V-C01-R01-D07012014-T123838-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg009-V-C01-R01-D07012014-T125159-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg010-V-C01-R01-D07012014-T130017-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg011-V-C01-R01-D07012014-T130817-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg012-V-C01-R01-D07012014-T131555-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg013-V-C01-R01-D07012014-T132418-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg014-V-C01-R01-D07012014-T133216-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg015-V-C01-R01-D07012014-T134017-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg016-V-C01-R01-D07012014-T134804-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg017-V-C01-R01-D07012014-T135606-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg018-V-C01-R01-D07012014-T140347-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg019-V-C01-R01-D07012014-T141205-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg020-V-C01-R01-D07012014-T141947-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg021-V-C01-R01-D07012014-T142741-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg022-V-C01-R01-D07012014-T143544-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg023-V-C01-R01-D07012014-T144313-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg024-V-C01-R01-D07012014-T145102-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg025-V-C01-R01-D07012014-T145841-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg026-V-C01-R01-D07012014-T150605-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg027-V-C01-R01-D08012014-T090247-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg028-V-C01-R01-D08012014-T091040-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg029-V-C01-R01-D08012014-T091856-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg030-V-C01-R01-D08012014-T092655-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg031-V-C01-R01-D08012014-T093502-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg032-V-C01-R01-D08012014-T094311-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg033-V-C01-R01-D08012014-T095051-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg034-V-C01-R01-D08012014-T113846-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg035-V-C01-R01-D08012014-T114709-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P598-Fg036-V-C01-R01-D08012014-T120010-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P590-Fg001-V-C01-R01-D13022013-T135759-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg002-V-C01-R01-D13022013-T140550-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg003-V-C01-R01-D13022013-T141418-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg004-V-C01-R01-D13022013-T142242-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P590-Fg005-V-C01-R01-D13022013-T143000-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg006-V-C01-R01-D13022013-T143743-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P590-Fg007-V-C01-R01-D13022013-T144828-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg008-V-C01-R01-D13022013-T145608-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg009-V-C01-R01-D13022013-T150444-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg010-V-C01-R01-D13022013-T151255-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg011-V-C01-R01-D13022013-T152054-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg012-V-C01-R01-D13022013-T152848-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg013-V-C01-R01-D13022013-T153927-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg014-V-C01-R01-D14022013-T110224-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P590-Fg015-V-C01-R01-D14022013-T111140-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P590-Fg016-V-C01-R01-D14022013-T124836-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg017-V-C01-R01-D14022013-T112907-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg018-V-C01-R01-D14022013-T113923-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg019-V-C01-R01-D14022013-T115234-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg020-V-C01-R01-D14022013-T120106-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P590-Fg021-V-C01-R01-D14022013-T121103-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg022-V-C01-R01-D14022013-T121948-LR924 _012.jpg\n",
      "extra crop\n",
      "/Volumes/250gb/cropped_bw/P590-Fg023-V-C01-R01-D14022013-T123002-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg024-V-C01-R01-D14022013-T123858-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg025-V-C01-R01-D14022013-T125702-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg026-V-C01-R01-D14022013-T141440-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg027-V-C01-R01-D14022013-T142305-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg028-V-C01-R01-D14022013-T143258-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg029-V-C01-R01-D14022013-T144229-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg030-V-C01-R01-D14022013-T145614-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg031-V-C01-R01-D14022013-T150437-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg032-V-C01-R01-D14022013-T151656-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg033-V-C01-R01-D14022013-T152630-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg034-V-C01-R01-D14022013-T153443-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P590-Fg035-V-C01-R01-D14022013-T154322-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P593-Fg001-V-C01-R01-D30122013-T143455-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg002-V-C01-R01-D30122013-T144317-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg003-V-C01-R01-D30122013-T145138-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg004-V-C01-R01-D30122013-T150013-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg005-V-C01-R01-D30122013-T151223-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg006-V-C01-R01-D30122013-T152129-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P593-Fg007-V-C01-R01-D30122013-T153001-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P593-Fg008-V-C01-R01-D30122013-T153837-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P593-Fg009-V-C01-R01-D30122013-T154659-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P593-Fg010-V-C01-R01-D31122013-T084620-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg011-V-C01-R01-D31122013-T085509-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg012-V-C01-R01-D31122013-T090401-LR924 _012.jpg\n",
      "/Volumes/250gb/cropped_bw/P593-Fg013-V-C01-R01-D31122013-T091238-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg014-V-C01-R01-D31122013-T092058-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg015-V-C01-R01-D31122013-T092847-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg016-V-C01-R01-D31122013-T093734-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg017-V-C01-R01-D31122013-T094521-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg018-V-C01-R01-D31122013-T095350-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg019-V-C01-R01-D31122013-T100322-LR924 _012.jpg\n",
      "no rotate\n",
      "/Volumes/250gb/cropped_bw/P593-Fg020-V-C01-R01-D31122013-T101105-LR924 _012.jpg\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "def read_and_select(files):\n",
    "    count = 0\n",
    "    for file_ in files:\n",
    "        image = img.imread(file_)\n",
    "        output = \"/Volumes/250gb/selected\"+file_[file_.rfind('/'):]\n",
    "        count += 1\n",
    "        img.imsave(output, image, cmap=plt.cm.gray)\n",
    "        print(output)\n",
    "    print(count)\n",
    "\n",
    "def read_and_write_cropped(files):\n",
    "    count = 0\n",
    "    for file_ in files:\n",
    "        image = read_full_path_and_crop(file_)\n",
    "        output_np = \"/Volumes/250gb/cropped\"+file_[file_.rfind('/'):]\n",
    "        output_img = \"/Volumes/250gb/cropped_bw\"+file_[file_.rfind('/'):]\n",
    "        count += 1\n",
    "        print(output_img)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        if file_[file_.rfind('/')+1:] in extra_crop:\n",
    "            print(\"extra crop\")\n",
    "            image = read_full_path_and_crop(file_, 0.97)\n",
    "\n",
    "        if file_[file_.rfind('/')+1:] not in no_rotate:\n",
    "            image = np.rot90(image)\n",
    "        else:\n",
    "            print(\"no rotate\")\n",
    "            \n",
    "#         if get_manual_orientation(image, False, 250) == 1:\n",
    "#             print(\"rotate\")\n",
    "#         image = np.rot90(image)\n",
    "        \n",
    "        np.save(output_np, image)\n",
    "        # cv2.imwrite(output, image)\n",
    "        plt.imsave(output_img, image, cmap=plt.cm.gray)\n",
    "        \n",
    "    print(count)\n",
    "        \n",
    "read_and_write_cropped(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
